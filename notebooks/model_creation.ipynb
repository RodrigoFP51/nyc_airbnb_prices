{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3473a182",
   "metadata": {},
   "source": [
    "## NYC Airbnb Price Prediction\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "354e7180",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "from feature_engine.encoding import RareLabelEncoder\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import (\n",
    "    OneHotEncoder, PowerTransformer, MinMaxScaler\n",
    ")\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import (\n",
    "    KFold, RandomizedSearchCV, train_test_split\n",
    ")\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_log_error, r2_score\n",
    ")\n",
    "\n",
    "pd.set_option('display.precision', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d9beff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Data/airbnb_imputed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11252d28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>34194.0</td>\n",
       "      <td>1.91e+07</td>\n",
       "      <td>1.10e+07</td>\n",
       "      <td>2539.00</td>\n",
       "      <td>9.51e+06</td>\n",
       "      <td>1.98e+07</td>\n",
       "      <td>2.92e+07</td>\n",
       "      <td>3.65e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_id</th>\n",
       "      <td>34194.0</td>\n",
       "      <td>6.78e+07</td>\n",
       "      <td>7.88e+07</td>\n",
       "      <td>2438.00</td>\n",
       "      <td>7.86e+06</td>\n",
       "      <td>3.09e+07</td>\n",
       "      <td>1.07e+08</td>\n",
       "      <td>2.74e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latitude</th>\n",
       "      <td>34194.0</td>\n",
       "      <td>4.07e+01</td>\n",
       "      <td>5.46e-02</td>\n",
       "      <td>40.51</td>\n",
       "      <td>4.07e+01</td>\n",
       "      <td>4.07e+01</td>\n",
       "      <td>4.08e+01</td>\n",
       "      <td>4.09e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longitude</th>\n",
       "      <td>34194.0</td>\n",
       "      <td>-7.40e+01</td>\n",
       "      <td>4.61e-02</td>\n",
       "      <td>-74.24</td>\n",
       "      <td>-7.40e+01</td>\n",
       "      <td>-7.40e+01</td>\n",
       "      <td>-7.39e+01</td>\n",
       "      <td>-7.37e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>34194.0</td>\n",
       "      <td>1.52e+02</td>\n",
       "      <td>2.35e+02</td>\n",
       "      <td>10.00</td>\n",
       "      <td>6.90e+01</td>\n",
       "      <td>1.05e+02</td>\n",
       "      <td>1.75e+02</td>\n",
       "      <td>1.00e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minimum_nights</th>\n",
       "      <td>34194.0</td>\n",
       "      <td>7.06e+00</td>\n",
       "      <td>2.07e+01</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00e+00</td>\n",
       "      <td>3.00e+00</td>\n",
       "      <td>5.00e+00</td>\n",
       "      <td>1.25e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_reviews</th>\n",
       "      <td>34194.0</td>\n",
       "      <td>2.32e+01</td>\n",
       "      <td>4.43e+01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00e+00</td>\n",
       "      <td>5.00e+00</td>\n",
       "      <td>2.30e+01</td>\n",
       "      <td>6.29e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviews_per_month</th>\n",
       "      <td>34194.0</td>\n",
       "      <td>1.16e+00</td>\n",
       "      <td>1.59e+00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.30e-01</td>\n",
       "      <td>5.10e-01</td>\n",
       "      <td>1.59e+00</td>\n",
       "      <td>5.85e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <td>34194.0</td>\n",
       "      <td>7.18e+00</td>\n",
       "      <td>3.30e+01</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00e+00</td>\n",
       "      <td>1.00e+00</td>\n",
       "      <td>2.00e+00</td>\n",
       "      <td>3.27e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>availability_365</th>\n",
       "      <td>34194.0</td>\n",
       "      <td>1.14e+02</td>\n",
       "      <td>1.32e+02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>4.60e+01</td>\n",
       "      <td>2.30e+02</td>\n",
       "      <td>3.65e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  count      mean       std      min  \\\n",
       "id                              34194.0  1.91e+07  1.10e+07  2539.00   \n",
       "host_id                         34194.0  6.78e+07  7.88e+07  2438.00   \n",
       "latitude                        34194.0  4.07e+01  5.46e-02    40.51   \n",
       "longitude                       34194.0 -7.40e+01  4.61e-02   -74.24   \n",
       "price                           34194.0  1.52e+02  2.35e+02    10.00   \n",
       "minimum_nights                  34194.0  7.06e+00  2.07e+01     1.00   \n",
       "number_of_reviews               34194.0  2.32e+01  4.43e+01     0.00   \n",
       "reviews_per_month               34194.0  1.16e+00  1.59e+00     0.01   \n",
       "calculated_host_listings_count  34194.0  7.18e+00  3.30e+01     1.00   \n",
       "availability_365                34194.0  1.14e+02  1.32e+02     0.00   \n",
       "\n",
       "                                     25%       50%       75%       max  \n",
       "id                              9.51e+06  1.98e+07  2.92e+07  3.65e+07  \n",
       "host_id                         7.86e+06  3.09e+07  1.07e+08  2.74e+08  \n",
       "latitude                        4.07e+01  4.07e+01  4.08e+01  4.09e+01  \n",
       "longitude                      -7.40e+01 -7.40e+01 -7.39e+01 -7.37e+01  \n",
       "price                           6.90e+01  1.05e+02  1.75e+02  1.00e+04  \n",
       "minimum_nights                  1.00e+00  3.00e+00  5.00e+00  1.25e+03  \n",
       "number_of_reviews               1.00e+00  5.00e+00  2.30e+01  6.29e+02  \n",
       "reviews_per_month               1.30e-01  5.10e-01  1.59e+00  5.85e+01  \n",
       "calculated_host_listings_count  1.00e+00  1.00e+00  2.00e+00  3.27e+02  \n",
       "availability_365                0.00e+00  4.60e+01  2.30e+02  3.65e+02  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d0e40df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <td>34194</td>\n",
       "      <td>33681</td>\n",
       "      <td>Hillside Hotel</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_name</th>\n",
       "      <td>34194</td>\n",
       "      <td>9148</td>\n",
       "      <td>Michael</td>\n",
       "      <td>309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_group</th>\n",
       "      <td>34194</td>\n",
       "      <td>5</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>15134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood</th>\n",
       "      <td>34194</td>\n",
       "      <td>217</td>\n",
       "      <td>Williamsburg</td>\n",
       "      <td>2718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>room_type</th>\n",
       "      <td>34194</td>\n",
       "      <td>3</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>17800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_review</th>\n",
       "      <td>34194</td>\n",
       "      <td>1675</td>\n",
       "      <td>2019-06-23</td>\n",
       "      <td>1212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     count unique              top   freq\n",
       "name                 34194  33681   Hillside Hotel     15\n",
       "host_name            34194   9148          Michael    309\n",
       "neighbourhood_group  34194      5        Manhattan  15134\n",
       "neighbourhood        34194    217     Williamsburg   2718\n",
       "room_type            34194      3  Entire home/apt  17800\n",
       "last_review          34194   1675       2019-06-23   1212"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include='object').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd875c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 34194 entries, 0 to 34193\n",
      "Data columns (total 16 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   id                              34194 non-null  int64  \n",
      " 1   name                            34194 non-null  object \n",
      " 2   host_id                         34194 non-null  int64  \n",
      " 3   host_name                       34194 non-null  object \n",
      " 4   neighbourhood_group             34194 non-null  object \n",
      " 5   neighbourhood                   34194 non-null  object \n",
      " 6   latitude                        34194 non-null  float64\n",
      " 7   longitude                       34194 non-null  float64\n",
      " 8   room_type                       34194 non-null  object \n",
      " 9   price                           34194 non-null  int64  \n",
      " 10  minimum_nights                  34194 non-null  int64  \n",
      " 11  number_of_reviews               34194 non-null  int64  \n",
      " 12  last_review                     34194 non-null  object \n",
      " 13  reviews_per_month               34194 non-null  float64\n",
      " 14  calculated_host_listings_count  34194 non-null  int64  \n",
      " 15  availability_365                34194 non-null  int64  \n",
      "dtypes: float64(3), int64(7), object(6)\n",
      "memory usage: 4.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1e7bfed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                0\n",
       "name                              0\n",
       "host_id                           0\n",
       "host_name                         0\n",
       "neighbourhood_group               0\n",
       "neighbourhood                     0\n",
       "latitude                          0\n",
       "longitude                         0\n",
       "room_type                         0\n",
       "price                             0\n",
       "minimum_nights                    0\n",
       "number_of_reviews                 0\n",
       "last_review                       0\n",
       "reviews_per_month                 0\n",
       "calculated_host_listings_count    0\n",
       "availability_365                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f599bef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = df.query(\"price > 0 & price < 800\")\n",
    "df['price'].hist(grid=False)\n",
    "#df = df[df['price']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d89d4a0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>host_id</th>\n",
       "      <th>host_name</th>\n",
       "      <th>neighbourhood_group</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>room_type</th>\n",
       "      <th>price</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>last_review</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>availability_365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>299531</td>\n",
       "      <td>Feel like you never leave your home</td>\n",
       "      <td>1220404</td>\n",
       "      <td>Tom</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>East New York</td>\n",
       "      <td>40.67</td>\n",
       "      <td>-73.89</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>119</td>\n",
       "      <td>2019-06-30</td>\n",
       "      <td>1.39</td>\n",
       "      <td>2</td>\n",
       "      <td>289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2461439</td>\n",
       "      <td>Pristine Lower East Side Sanctuary</td>\n",
       "      <td>12586492</td>\n",
       "      <td>Sausan</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Lower East Side</td>\n",
       "      <td>40.72</td>\n",
       "      <td>-73.99</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>133</td>\n",
       "      <td>14</td>\n",
       "      <td>177</td>\n",
       "      <td>2019-05-03</td>\n",
       "      <td>2.82</td>\n",
       "      <td>2</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>127387</td>\n",
       "      <td>Luxe, Spacious 2BR 2BA Nr Trains</td>\n",
       "      <td>23276</td>\n",
       "      <td>Katharine</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Gowanus</td>\n",
       "      <td>40.67</td>\n",
       "      <td>-73.99</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>260</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>2014-08-04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1</td>\n",
       "      <td>316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>629315</td>\n",
       "      <td>1BD brownstone apt in Fort Greene!</td>\n",
       "      <td>2397437</td>\n",
       "      <td>Lauren</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Fort Greene</td>\n",
       "      <td>40.69</td>\n",
       "      <td>-73.97</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>120</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>2015-10-28</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4607923</td>\n",
       "      <td>LOVELY  LARGE SUNNY ROOM    Sunset Park</td>\n",
       "      <td>1113080</td>\n",
       "      <td>Audrey</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Sunset Park</td>\n",
       "      <td>40.65</td>\n",
       "      <td>-74.00</td>\n",
       "      <td>Private room</td>\n",
       "      <td>55</td>\n",
       "      <td>7</td>\n",
       "      <td>98</td>\n",
       "      <td>2019-05-22</td>\n",
       "      <td>1.75</td>\n",
       "      <td>3</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34189</th>\n",
       "      <td>32786275</td>\n",
       "      <td>Clean and Simple</td>\n",
       "      <td>82940021</td>\n",
       "      <td>Todd</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Hell's Kitchen</td>\n",
       "      <td>40.76</td>\n",
       "      <td>-73.99</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>145</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34190</th>\n",
       "      <td>29829054</td>\n",
       "      <td>Best location in Williamsburg!</td>\n",
       "      <td>20827165</td>\n",
       "      <td>Melissa</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Williamsburg</td>\n",
       "      <td>40.72</td>\n",
       "      <td>-73.94</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>99</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-11-19</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34191</th>\n",
       "      <td>31857472</td>\n",
       "      <td>Hamilton Studio. 2Queen. priv bath. kitchenette</td>\n",
       "      <td>238750007</td>\n",
       "      <td>Hamilton</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Harlem</td>\n",
       "      <td>40.82</td>\n",
       "      <td>-73.95</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>145</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>2019-07-02</td>\n",
       "      <td>3.66</td>\n",
       "      <td>3</td>\n",
       "      <td>310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34192</th>\n",
       "      <td>19197129</td>\n",
       "      <td>Best CoLiving next to Bushwick!</td>\n",
       "      <td>134293540</td>\n",
       "      <td>Valentin</td>\n",
       "      <td>Queens</td>\n",
       "      <td>Ridgewood</td>\n",
       "      <td>40.71</td>\n",
       "      <td>-73.90</td>\n",
       "      <td>Shared room</td>\n",
       "      <td>26</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>2018-05-04</td>\n",
       "      <td>0.22</td>\n",
       "      <td>4</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34193</th>\n",
       "      <td>33854066</td>\n",
       "      <td>Birdman movie Room in Brooklyn.30 Min to Manha...</td>\n",
       "      <td>255448841</td>\n",
       "      <td>Andrey</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Bedford-Stuyvesant</td>\n",
       "      <td>40.68</td>\n",
       "      <td>-73.91</td>\n",
       "      <td>Private room</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>2019-07-07</td>\n",
       "      <td>5.49</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33874 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                               name    host_id  \\\n",
       "0        299531                Feel like you never leave your home    1220404   \n",
       "1       2461439                 Pristine Lower East Side Sanctuary   12586492   \n",
       "2        127387                   Luxe, Spacious 2BR 2BA Nr Trains      23276   \n",
       "3        629315                 1BD brownstone apt in Fort Greene!    2397437   \n",
       "4       4607923            LOVELY  LARGE SUNNY ROOM    Sunset Park    1113080   \n",
       "...         ...                                                ...        ...   \n",
       "34189  32786275                                   Clean and Simple   82940021   \n",
       "34190  29829054                     Best location in Williamsburg!   20827165   \n",
       "34191  31857472    Hamilton Studio. 2Queen. priv bath. kitchenette  238750007   \n",
       "34192  19197129                    Best CoLiving next to Bushwick!  134293540   \n",
       "34193  33854066  Birdman movie Room in Brooklyn.30 Min to Manha...  255448841   \n",
       "\n",
       "       host_name neighbourhood_group       neighbourhood  latitude  longitude  \\\n",
       "0            Tom            Brooklyn       East New York     40.67     -73.89   \n",
       "1         Sausan           Manhattan     Lower East Side     40.72     -73.99   \n",
       "2      Katharine            Brooklyn             Gowanus     40.67     -73.99   \n",
       "3         Lauren            Brooklyn         Fort Greene     40.69     -73.97   \n",
       "4         Audrey            Brooklyn         Sunset Park     40.65     -74.00   \n",
       "...          ...                 ...                 ...       ...        ...   \n",
       "34189       Todd           Manhattan      Hell's Kitchen     40.76     -73.99   \n",
       "34190    Melissa            Brooklyn        Williamsburg     40.72     -73.94   \n",
       "34191   Hamilton           Manhattan              Harlem     40.82     -73.95   \n",
       "34192   Valentin              Queens           Ridgewood     40.71     -73.90   \n",
       "34193     Andrey            Brooklyn  Bedford-Stuyvesant     40.68     -73.91   \n",
       "\n",
       "             room_type  price  minimum_nights  number_of_reviews last_review  \\\n",
       "0      Entire home/apt    100               1                119  2019-06-30   \n",
       "1      Entire home/apt    133              14                177  2019-05-03   \n",
       "2      Entire home/apt    260              30                  3  2014-08-04   \n",
       "3      Entire home/apt    120               3                 22  2015-10-28   \n",
       "4         Private room     55               7                 98  2019-05-22   \n",
       "...                ...    ...             ...                ...         ...   \n",
       "34189  Entire home/apt    145               3                  9  2019-07-01   \n",
       "34190  Entire home/apt     99               2                  1  2018-11-19   \n",
       "34191  Entire home/apt    145               4                 20  2019-07-02   \n",
       "34192      Shared room     26              31                  5  2018-05-04   \n",
       "34193     Private room     55               1                 15  2019-07-07   \n",
       "\n",
       "       reviews_per_month  calculated_host_listings_count  availability_365  \n",
       "0                   1.39                               2               289  \n",
       "1                   2.82                               2               221  \n",
       "2                   0.03                               1               316  \n",
       "3                   0.27                               1               189  \n",
       "4                   1.75                               3               312  \n",
       "...                  ...                             ...               ...  \n",
       "34189               3.55                               1                 6  \n",
       "34190               0.13                               2                 0  \n",
       "34191               3.66                               3               310  \n",
       "34192               0.22                               4               365  \n",
       "34193               5.49                               3                20  \n",
       "\n",
       "[33874 rows x 16 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['last_review'] = pd.to_datetime(df['last_review'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "651dab9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                         int64\n",
       "name                                      object\n",
       "host_id                                    int64\n",
       "host_name                                 object\n",
       "neighbourhood_group                       object\n",
       "neighbourhood                             object\n",
       "latitude                                 float64\n",
       "longitude                                float64\n",
       "room_type                                 object\n",
       "price                                    float64\n",
       "minimum_nights                             int64\n",
       "number_of_reviews                          int64\n",
       "last_review                       datetime64[ns]\n",
       "reviews_per_month                        float64\n",
       "calculated_host_listings_count             int64\n",
       "availability_365                           int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['price'] = df['price'].astype(\"float64\")\n",
    "df['name'] = df['name'].astype(object)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc74572f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15619</th>\n",
       "      <td>2016</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30302</th>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20805</th>\n",
       "      <td>2019</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6938</th>\n",
       "      <td>2018</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22376</th>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       year  month\n",
       "15619  2016      7\n",
       "30302  2019      2\n",
       "20805  2019      7\n",
       "6938   2018      7\n",
       "22376  2017     12"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['year'] = df.last_review.dt.year\n",
    "df['month'] = df.last_review.dt.month\n",
    "\n",
    "df[['year','month']].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "20c0d636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    name neighbourhood_group  \\\n",
      "17012                            Great Williamsburg Spot            Brooklyn   \n",
      "6310   Private room in East Harlem close to heart of NYC           Manhattan   \n",
      "11385                 Cozy 1 BD apartment in Sunset park            Brooklyn   \n",
      "864             ENJOY MANHATTAN\\r\\nNEAR TO YANKE STADIUM               Bronx   \n",
      "15944                    Large & bright 900ft² 1br in WV           Manhattan   \n",
      "\n",
      "      neighbourhood        room_type  minimum_nights  number_of_reviews  \\\n",
      "17012  Williamsburg     Private room               2                  0   \n",
      "6310    East Harlem     Private room               2                  0   \n",
      "11385   Sunset Park  Entire home/apt               1                 26   \n",
      "864      Mott Haven     Private room               1                 29   \n",
      "15944  West Village  Entire home/apt               4                  6   \n",
      "\n",
      "      last_review  reviews_per_month  calculated_host_listings_count  \\\n",
      "17012  2019-07-06               0.13                               2   \n",
      "6310   2019-06-27               0.02                               1   \n",
      "11385  2019-03-24               2.52                               1   \n",
      "864    2019-06-28               3.15                               4   \n",
      "15944  2017-06-28               0.16                               1   \n",
      "\n",
      "       availability_365  \n",
      "17012                86  \n",
      "6310                  0  \n",
      "11385                 0  \n",
      "864                 312  \n",
      "15944                 0  \n"
     ]
    }
   ],
   "source": [
    "X = df.drop(['price', 'host_id', 'host_name', 'id','longitude','latitude'],axis = 1)\n",
    "y = np.log(df['price'])\n",
    "\n",
    "num_cols = X.select_dtypes(include = np.number).columns.to_list()\n",
    "cat_cols = X.select_dtypes(exclude = np.number).drop(['name','last_review'], axis=1).columns.to_list()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "\n",
    "print(X_train.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "229579da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "pipe_cat = Pipeline(\n",
    "    steps = [\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe_num = Pipeline(\n",
    "    steps = [\n",
    "    ('scale', MinMaxScaler())\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe_text = Pipeline(\n",
    "    steps = [\n",
    "        ('text_vec', CountVectorizer(analyzer='word',\n",
    "                                     stop_words='english',\n",
    "                                     max_features=30))\n",
    "    ]\n",
    ")\n",
    "\n",
    "#pd.DataFrame(pipe_text.fit_transform(X_train['name']).toarray(), columns=pipe_text.get_feature_names_out())[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "931fcfc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text__apartment</th>\n",
       "      <th>text__apt</th>\n",
       "      <th>text__beautiful</th>\n",
       "      <th>text__bed</th>\n",
       "      <th>text__bedroom</th>\n",
       "      <th>text__bright</th>\n",
       "      <th>text__brooklyn</th>\n",
       "      <th>text__central</th>\n",
       "      <th>text__cozy</th>\n",
       "      <th>text__east</th>\n",
       "      <th>...</th>\n",
       "      <th>cat__neighbourhood_Woodside</th>\n",
       "      <th>cat__room_type_Entire home/apt</th>\n",
       "      <th>cat__room_type_Private room</th>\n",
       "      <th>cat__room_type_Shared room</th>\n",
       "      <th>remainder__minimum_nights</th>\n",
       "      <th>remainder__number_of_reviews</th>\n",
       "      <th>remainder__last_review</th>\n",
       "      <th>remainder__reviews_per_month</th>\n",
       "      <th>remainder__calculated_host_listings_count</th>\n",
       "      <th>remainder__availability_365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2018-02-26</td>\n",
       "      <td>0.11</td>\n",
       "      <td>2</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>122</td>\n",
       "      <td>2019-06-17</td>\n",
       "      <td>5.42</td>\n",
       "      <td>1</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2019-05-26</td>\n",
       "      <td>1.69</td>\n",
       "      <td>327</td>\n",
       "      <td>337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-06-23</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>2019-06-05</td>\n",
       "      <td>3.37</td>\n",
       "      <td>1</td>\n",
       "      <td>285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-11-06</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>2019-05-28</td>\n",
       "      <td>1.62</td>\n",
       "      <td>1</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>2019-06-14</td>\n",
       "      <td>3.59</td>\n",
       "      <td>1</td>\n",
       "      <td>271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>2019-07-06</td>\n",
       "      <td>10.31</td>\n",
       "      <td>3</td>\n",
       "      <td>347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-11-03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>68</td>\n",
       "      <td>2019-07-04</td>\n",
       "      <td>5.37</td>\n",
       "      <td>1</td>\n",
       "      <td>247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-10-11</td>\n",
       "      <td>0.08</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>2019-07-04</td>\n",
       "      <td>3.54</td>\n",
       "      <td>2</td>\n",
       "      <td>304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-09-04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1</td>\n",
       "      <td>332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2017-04-21</td>\n",
       "      <td>0.11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-04-21</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2019-05-20</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-07-05</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>2019-06-19</td>\n",
       "      <td>3.31</td>\n",
       "      <td>4</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 258 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   text__apartment text__apt text__beautiful text__bed text__bedroom  \\\n",
       "0                0         0               0         0             0   \n",
       "1                0         0               0         0             0   \n",
       "2                0         0               0         0             0   \n",
       "3                0         0               0         0             1   \n",
       "4                0         0               0         0             0   \n",
       "5                0         1               0         0             0   \n",
       "6                0         1               0         0             0   \n",
       "7                1         0               0         0             0   \n",
       "8                1         0               0         0             0   \n",
       "9                0         0               0         0             1   \n",
       "10               0         0               0         0             0   \n",
       "11               0         0               0         0             0   \n",
       "12               0         0               0         0             0   \n",
       "13               0         0               0         0             1   \n",
       "14               1         0               0         0             0   \n",
       "15               0         1               0         0             1   \n",
       "16               0         0               0         2             0   \n",
       "17               0         0               0         0             0   \n",
       "18               1         0               0         0             0   \n",
       "19               0         0               0         0             0   \n",
       "\n",
       "   text__bright text__brooklyn text__central text__cozy text__east  ...  \\\n",
       "0             0              0             0          0          0  ...   \n",
       "1             1              0             0          0          0  ...   \n",
       "2             0              0             0          0          0  ...   \n",
       "3             0              0             0          0          0  ...   \n",
       "4             0              0             0          0          0  ...   \n",
       "5             0              0             0          0          0  ...   \n",
       "6             0              0             0          0          0  ...   \n",
       "7             0              0             0          0          0  ...   \n",
       "8             0              1             0          1          0  ...   \n",
       "9             0              1             0          0          0  ...   \n",
       "10            0              0             0          0          0  ...   \n",
       "11            0              0             0          1          0  ...   \n",
       "12            0              1             0          0          0  ...   \n",
       "13            1              0             1          0          0  ...   \n",
       "14            0              0             0          0          0  ...   \n",
       "15            0              0             0          0          0  ...   \n",
       "16            0              0             0          0          0  ...   \n",
       "17            0              1             0          0          0  ...   \n",
       "18            0              0             0          0          0  ...   \n",
       "19            0              0             0          0          0  ...   \n",
       "\n",
       "   cat__neighbourhood_Woodside cat__room_type_Entire home/apt  \\\n",
       "0                          0.0                            0.0   \n",
       "1                          0.0                            1.0   \n",
       "2                          0.0                            1.0   \n",
       "3                          0.0                            0.0   \n",
       "4                          0.0                            0.0   \n",
       "5                          0.0                            0.0   \n",
       "6                          0.0                            1.0   \n",
       "7                          0.0                            1.0   \n",
       "8                          0.0                            1.0   \n",
       "9                          0.0                            0.0   \n",
       "10                         0.0                            0.0   \n",
       "11                         0.0                            1.0   \n",
       "12                         0.0                            0.0   \n",
       "13                         0.0                            0.0   \n",
       "14                         0.0                            1.0   \n",
       "15                         0.0                            1.0   \n",
       "16                         0.0                            0.0   \n",
       "17                         0.0                            0.0   \n",
       "18                         0.0                            0.0   \n",
       "19                         0.0                            0.0   \n",
       "\n",
       "   cat__room_type_Private room cat__room_type_Shared room  \\\n",
       "0                          1.0                        0.0   \n",
       "1                          0.0                        0.0   \n",
       "2                          0.0                        0.0   \n",
       "3                          1.0                        0.0   \n",
       "4                          1.0                        0.0   \n",
       "5                          1.0                        0.0   \n",
       "6                          0.0                        0.0   \n",
       "7                          0.0                        0.0   \n",
       "8                          0.0                        0.0   \n",
       "9                          1.0                        0.0   \n",
       "10                         1.0                        0.0   \n",
       "11                         0.0                        0.0   \n",
       "12                         1.0                        0.0   \n",
       "13                         1.0                        0.0   \n",
       "14                         0.0                        0.0   \n",
       "15                         0.0                        0.0   \n",
       "16                         1.0                        0.0   \n",
       "17                         1.0                        0.0   \n",
       "18                         1.0                        0.0   \n",
       "19                         1.0                        0.0   \n",
       "\n",
       "   remainder__minimum_nights remainder__number_of_reviews  \\\n",
       "0                          2                            2   \n",
       "1                          1                          122   \n",
       "2                          2                            7   \n",
       "3                          7                            0   \n",
       "4                          1                           23   \n",
       "5                          3                            1   \n",
       "6                          3                           40   \n",
       "7                          3                           22   \n",
       "8                          1                           14   \n",
       "9                          1                           22   \n",
       "10                         2                            1   \n",
       "11                         2                           68   \n",
       "12                         2                            3   \n",
       "13                         1                           29   \n",
       "14                         6                            0   \n",
       "15                         2                            3   \n",
       "16                         1                            0   \n",
       "17                         2                            6   \n",
       "18                         2                            2   \n",
       "19                         1                           44   \n",
       "\n",
       "   remainder__last_review remainder__reviews_per_month  \\\n",
       "0              2018-02-26                         0.11   \n",
       "1              2019-06-17                         5.42   \n",
       "2              2019-05-26                         1.69   \n",
       "3              2019-06-23                         0.34   \n",
       "4              2019-06-05                         3.37   \n",
       "5              2017-11-06                         0.05   \n",
       "6              2019-01-01                         1.04   \n",
       "7              2019-05-28                         1.62   \n",
       "8              2019-06-14                         3.59   \n",
       "9              2019-07-06                        10.31   \n",
       "10             2015-11-03                         0.02   \n",
       "11             2019-07-04                         5.37   \n",
       "12             2016-10-11                         0.08   \n",
       "13             2019-07-04                         3.54   \n",
       "14             2017-09-04                         0.02   \n",
       "15             2017-04-21                         0.11   \n",
       "16             2019-04-21                         0.02   \n",
       "17             2019-05-20                         0.12   \n",
       "18             2019-07-05                         0.21   \n",
       "19             2019-06-19                         3.31   \n",
       "\n",
       "   remainder__calculated_host_listings_count remainder__availability_365  \n",
       "0                                          2                          90  \n",
       "1                                          1                         193  \n",
       "2                                        327                         337  \n",
       "3                                          1                           0  \n",
       "4                                          1                         285  \n",
       "5                                          1                           0  \n",
       "6                                          2                         189  \n",
       "7                                          1                         278  \n",
       "8                                          1                         271  \n",
       "9                                          3                         347  \n",
       "10                                         1                           0  \n",
       "11                                         1                         247  \n",
       "12                                         3                          12  \n",
       "13                                         2                         304  \n",
       "14                                         1                         332  \n",
       "15                                         1                           0  \n",
       "16                                         1                           0  \n",
       "17                                         1                         365  \n",
       "18                                         1                          22  \n",
       "19                                         4                          59  \n",
       "\n",
       "[20 rows x 258 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers = [\n",
    "    #('num', pipe_num, num_cols),\n",
    "    ('text', pipe_text, 'name'),\n",
    "    ('cat', pipe_cat, cat_cols)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "pd.DataFrame(preprocess.fit_transform(X_train), columns=preprocess.get_feature_names_out()).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "074efe02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_engine.datetime import DatetimeFeatures\n",
    "model = Pipeline(steps = [\n",
    "    ('date_features', DatetimeFeatures(features_to_extract=['year','month','quarter','day_of_week','weekend'], variables=['last_review'])),\n",
    "    ('rare', RareLabelEncoder(tol=0.03, variables=['neighbourhood'])),\n",
    "    ('preprocessor', preprocess),\n",
    "    ('lgbm', LGBMRegressor())\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5261a55d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004380 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1015\n",
      "[LightGBM] [Info] Number of data points in the train set: 23711, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 4.704162\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6246039359392623"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fit = model.fit(X_train, y_train) \n",
    "model_fit.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bf107b1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.48466006, 4.79991346, 3.3807924 , ..., 5.20799278, 4.75096473,\n",
       "       4.51566235])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model_fit.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "179c7f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE for LGBM: 0.0701942935530983,\n",
      "R2 for LGBM: 0.6246039359392623\n"
     ]
    }
   ],
   "source": [
    "print(f\"RMSLE for LGBM: {np.sqrt(mean_squared_log_error(y_test, y_pred))},\\\n",
    "\\nR2 for LGBM: {r2_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "698431fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huber R2: 0.46612923095701175\n",
      "          huber RMSLE: 0.08530211188381726\n",
      "gb R2: 0.6021125541212128\n",
      "          gb RMSLE: 0.07219894622642901\n",
      "ada R2: 0.4436865584218058\n",
      "          ada RMSLE: 0.0864200945599825\n",
      "xgb R2: 0.6164807034268014\n",
      "          xgb RMSLE: 0.07098634158758446\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import HuberRegressor\n",
    "from sklearn.ensemble import (\n",
    "    GradientBoostingRegressor, AdaBoostRegressor\n",
    ")\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "models = [\n",
    "    ('huber', HuberRegressor()),\n",
    "    ('gb', GradientBoostingRegressor()),\n",
    "    ('ada', AdaBoostRegressor()),\n",
    "    ('xgb', XGBRegressor())\n",
    "] \n",
    "\n",
    "for name, model in models:\n",
    "    pipe = Pipeline(steps=[\n",
    "        ('date_features', DatetimeFeatures(features_to_extract=['year','month','quarter','day_of_week','weekend'], variables=['last_review'])),\n",
    "        ('rare', RareLabelEncoder(tol=0.03, variables=['neighbourhood'])),\n",
    "        ('preprocessor', preprocess),\n",
    "        (name, model)\n",
    "    ])\n",
    "    \n",
    "    pipe.fit(X_train,y_train)\n",
    "    preds = pipe.predict(X_test)\n",
    "    print(f\"\"\"{name} R2: {r2_score(y_test, preds)}\n",
    "          {name} RMSLE: {np.sqrt(mean_squared_log_error(y_test, preds))}\"\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0279e825",
   "metadata": {},
   "source": [
    "## Otimização dos parâmetros do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4955b835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['memory', 'steps', 'verbose', 'date_features', 'rare', 'preprocessor', 'lgbm', 'date_features__dayfirst', 'date_features__drop_original', 'date_features__features_to_extract', 'date_features__format', 'date_features__missing_values', 'date_features__utc', 'date_features__variables', 'date_features__yearfirst', 'rare__ignore_format', 'rare__max_n_categories', 'rare__missing_values', 'rare__n_categories', 'rare__replace_with', 'rare__tol', 'rare__variables', 'preprocessor__n_jobs', 'preprocessor__remainder', 'preprocessor__sparse_threshold', 'preprocessor__transformer_weights', 'preprocessor__transformers', 'preprocessor__verbose', 'preprocessor__verbose_feature_names_out', 'preprocessor__text', 'preprocessor__cat', 'preprocessor__text__memory', 'preprocessor__text__steps', 'preprocessor__text__verbose', 'preprocessor__text__text_vec', 'preprocessor__text__text_vec__analyzer', 'preprocessor__text__text_vec__binary', 'preprocessor__text__text_vec__decode_error', 'preprocessor__text__text_vec__dtype', 'preprocessor__text__text_vec__encoding', 'preprocessor__text__text_vec__input', 'preprocessor__text__text_vec__lowercase', 'preprocessor__text__text_vec__max_df', 'preprocessor__text__text_vec__max_features', 'preprocessor__text__text_vec__min_df', 'preprocessor__text__text_vec__ngram_range', 'preprocessor__text__text_vec__preprocessor', 'preprocessor__text__text_vec__stop_words', 'preprocessor__text__text_vec__strip_accents', 'preprocessor__text__text_vec__token_pattern', 'preprocessor__text__text_vec__tokenizer', 'preprocessor__text__text_vec__vocabulary', 'preprocessor__cat__memory', 'preprocessor__cat__steps', 'preprocessor__cat__verbose', 'preprocessor__cat__encoder', 'preprocessor__cat__encoder__categories', 'preprocessor__cat__encoder__drop', 'preprocessor__cat__encoder__dtype', 'preprocessor__cat__encoder__feature_name_combiner', 'preprocessor__cat__encoder__handle_unknown', 'preprocessor__cat__encoder__max_categories', 'preprocessor__cat__encoder__min_frequency', 'preprocessor__cat__encoder__sparse', 'preprocessor__cat__encoder__sparse_output', 'lgbm__boosting_type', 'lgbm__class_weight', 'lgbm__colsample_bytree', 'lgbm__importance_type', 'lgbm__learning_rate', 'lgbm__max_depth', 'lgbm__min_child_samples', 'lgbm__min_child_weight', 'lgbm__min_split_gain', 'lgbm__n_estimators', 'lgbm__n_jobs', 'lgbm__num_leaves', 'lgbm__objective', 'lgbm__random_state', 'lgbm__reg_alpha', 'lgbm__reg_lambda', 'lgbm__subsample', 'lgbm__subsample_for_bin', 'lgbm__subsample_freq'])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_grid = {\n",
    "    'lgbm__num_leaves': [7, 14, 21],\n",
    "    'lgbm__learning_rate': [0.1, 0.03, 0.001],\n",
    "    'lgbm__max_depth': [-1, 3, 5],\n",
    "    'lgbm__n_estimators': [200, 500, 1000],\n",
    "    'preprocessor__text__text_vec__max_features': [10,20,50,150]\n",
    "}\n",
    "\n",
    "model.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2762de79",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_tune = RandomizedSearchCV(\n",
    "    model, \n",
    "    param_distributions = lgbm_grid,\n",
    "    cv = 5,\n",
    "    scoring = 'neg_mean_squared_log_error',\n",
    "    return_train_score = True,\n",
    "    n_iter = 10,\n",
    "    verbose = 1,\n",
    "    random_state = 42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8ec1cd0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002999 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 950\n",
      "[LightGBM] [Info] Number of data points in the train set: 18968, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 4.702090\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002483 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 950\n",
      "[LightGBM] [Info] Number of data points in the train set: 18969, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 4.703432\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003149 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 950\n",
      "[LightGBM] [Info] Number of data points in the train set: 18969, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 4.705202\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001854 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 949\n",
      "[LightGBM] [Info] Number of data points in the train set: 18969, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 4.705213\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001867 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 950\n",
      "[LightGBM] [Info] Number of data points in the train set: 18969, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 4.704875\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002994 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 950\n",
      "[LightGBM] [Info] Number of data points in the train set: 18968, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 4.702090\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002041 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 950\n",
      "[LightGBM] [Info] Number of data points in the train set: 18969, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 4.703432\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002441 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 950\n",
      "[LightGBM] [Info] Number of data points in the train set: 18969, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 4.705202\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002222 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 949\n",
      "[LightGBM] [Info] Number of data points in the train set: 18969, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 4.705213\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003191 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 950\n",
      "[LightGBM] [Info] Number of data points in the train set: 18969, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 4.704875\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002087 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 975\n",
      "[LightGBM] [Info] Number of data points in the train set: 18968, number of used features: 49\n",
      "[LightGBM] [Info] Start training from score 4.702090\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002932 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 977\n",
      "[LightGBM] [Info] Number of data points in the train set: 18969, number of used features: 49\n",
      "[LightGBM] [Info] Start training from score 4.703432\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002769 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 977\n",
      "[LightGBM] [Info] Number of data points in the train set: 18969, number of used features: 49\n",
      "[LightGBM] [Info] Start training from score 4.705202\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002118 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 976\n",
      "[LightGBM] [Info] Number of data points in the train set: 18969, number of used features: 49\n",
      "[LightGBM] [Info] Start training from score 4.705213\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002855 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 977\n",
      "[LightGBM] [Info] Number of data points in the train set: 18969, number of used features: 49\n",
      "[LightGBM] [Info] Start training from score 4.704875\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003571 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 975\n",
      "[LightGBM] [Info] Number of data points in the train set: 18968, number of used features: 49\n",
      "[LightGBM] [Info] Start training from score 4.702090\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003021 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 977\n",
      "[LightGBM] [Info] Number of data points in the train set: 18969, number of used features: 49\n",
      "[LightGBM] [Info] Start training from score 4.703432\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002929 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 977\n",
      "[LightGBM] [Info] Number of data points in the train set: 18969, number of used features: 49\n",
      "[LightGBM] [Info] Start training from score 4.705202\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003364 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 976\n",
      "[LightGBM] [Info] Number of data points in the train set: 18969, number of used features: 49\n",
      "[LightGBM] [Info] Start training from score 4.705213\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001990 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 977\n",
      "[LightGBM] [Info] Number of data points in the train set: 18969, number of used features: 49\n",
      "[LightGBM] [Info] Start training from score 4.704875\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002213 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 950\n",
      "[LightGBM] [Info] Number of data points in the train set: 18968, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 4.702090\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002364 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 950\n",
      "[LightGBM] [Info] Number of data points in the train set: 18969, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 4.703432\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002230 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 950\n",
      "[LightGBM] [Info] Number of data points in the train set: 18969, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 4.705202\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002745 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 949\n",
      "[LightGBM] [Info] Number of data points in the train set: 18969, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 4.705213\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001824 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 950\n",
      "[LightGBM] [Info] Number of data points in the train set: 18969, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 4.704875\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003819 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1054\n",
      "[LightGBM] [Info] Number of data points in the train set: 18968, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 4.702090\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003288 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1057\n",
      "[LightGBM] [Info] Number of data points in the train set: 18969, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 4.703432\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005419 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1058\n",
      "[LightGBM] [Info] Number of data points in the train set: 18969, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 4.705202\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004342 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1055\n",
      "[LightGBM] [Info] Number of data points in the train set: 18969, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 4.705213\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004869 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1058\n",
      "[LightGBM] [Info] Number of data points in the train set: 18969, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 4.704875\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010894 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1278\n",
      "[LightGBM] [Info] Number of data points in the train set: 18968, number of used features: 179\n",
      "[LightGBM] [Info] Start training from score 4.702090\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012984 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1279\n",
      "[LightGBM] [Info] Number of data points in the train set: 18969, number of used features: 179\n",
      "[LightGBM] [Info] Start training from score 4.703432\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009528 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1284\n",
      "[LightGBM] [Info] Number of data points in the train set: 18969, number of used features: 179\n",
      "[LightGBM] [Info] Start training from score 4.705202\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007017 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1279\n",
      "[LightGBM] [Info] Number of data points in the train set: 18969, number of used features: 179\n",
      "[LightGBM] [Info] Start training from score 4.705213\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011057 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1283\n",
      "[LightGBM] [Info] Number of data points in the train set: 18969, number of used features: 179\n",
      "[LightGBM] [Info] Start training from score 4.704875\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002723 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 950\n",
      "[LightGBM] [Info] Number of data points in the train set: 18968, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 4.702090\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002753 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 950\n",
      "[LightGBM] [Info] Number of data points in the train set: 18969, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 4.703432\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002606 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 950\n",
      "[LightGBM] [Info] Number of data points in the train set: 18969, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 4.705202\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002188 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 949\n",
      "[LightGBM] [Info] Number of data points in the train set: 18969, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 4.705213\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002334 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 950\n",
      "[LightGBM] [Info] Number of data points in the train set: 18969, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 4.704875\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005870 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1054\n",
      "[LightGBM] [Info] Number of data points in the train set: 18968, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 4.702090\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004376 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1057\n",
      "[LightGBM] [Info] Number of data points in the train set: 18969, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 4.703432\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004612 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1058\n",
      "[LightGBM] [Info] Number of data points in the train set: 18969, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 4.705202\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004439 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1055\n",
      "[LightGBM] [Info] Number of data points in the train set: 18969, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 4.705213\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007128 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1058\n",
      "[LightGBM] [Info] Number of data points in the train set: 18969, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 4.704875\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002648 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 950\n",
      "[LightGBM] [Info] Number of data points in the train set: 18968, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 4.702090\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001741 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 950\n",
      "[LightGBM] [Info] Number of data points in the train set: 18969, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 4.703432\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002471 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 950\n",
      "[LightGBM] [Info] Number of data points in the train set: 18969, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 4.705202\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002431 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 949\n",
      "[LightGBM] [Info] Number of data points in the train set: 18969, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 4.705213\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002495 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 950\n",
      "[LightGBM] [Info] Number of data points in the train set: 18969, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 4.704875\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006428 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1066\n",
      "[LightGBM] [Info] Number of data points in the train set: 23711, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 4.704162\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[(&#x27;date_features&#x27;,\n",
       "                                              DatetimeFeatures(features_to_extract=[&#x27;year&#x27;,\n",
       "                                                                                    &#x27;month&#x27;,\n",
       "                                                                                    &#x27;quarter&#x27;,\n",
       "                                                                                    &#x27;day_of_week&#x27;,\n",
       "                                                                                    &#x27;weekend&#x27;],\n",
       "                                                               variables=[&#x27;last_review&#x27;])),\n",
       "                                             (&#x27;rare&#x27;,\n",
       "                                              RareLabelEncoder(tol=0.03,\n",
       "                                                               variables=[&#x27;neighbourhood&#x27;])),\n",
       "                                             (&#x27;preprocessor&#x27;,\n",
       "                                              ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                                                transformers=[(&#x27;text&#x27;,\n",
       "                                                                               Pipeline(steps=[(&#x27;text_...\n",
       "                                                                                &#x27;neighbourhood&#x27;,\n",
       "                                                                                &#x27;room_type&#x27;])])),\n",
       "                                             (&#x27;lgbm&#x27;, LGBMRegressor())]),\n",
       "                   param_distributions={&#x27;lgbm__learning_rate&#x27;: [0.1, 0.03,\n",
       "                                                                0.001],\n",
       "                                        &#x27;lgbm__max_depth&#x27;: [-1, 3, 5],\n",
       "                                        &#x27;lgbm__n_estimators&#x27;: [200, 500, 1000],\n",
       "                                        &#x27;lgbm__num_leaves&#x27;: [7, 14, 21],\n",
       "                                        &#x27;preprocessor__text__text_vec__max_features&#x27;: [10,\n",
       "                                                                                       20,\n",
       "                                                                                       50,\n",
       "                                                                                       150]},\n",
       "                   random_state=42, return_train_score=True,\n",
       "                   scoring=&#x27;neg_mean_squared_log_error&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[(&#x27;date_features&#x27;,\n",
       "                                              DatetimeFeatures(features_to_extract=[&#x27;year&#x27;,\n",
       "                                                                                    &#x27;month&#x27;,\n",
       "                                                                                    &#x27;quarter&#x27;,\n",
       "                                                                                    &#x27;day_of_week&#x27;,\n",
       "                                                                                    &#x27;weekend&#x27;],\n",
       "                                                               variables=[&#x27;last_review&#x27;])),\n",
       "                                             (&#x27;rare&#x27;,\n",
       "                                              RareLabelEncoder(tol=0.03,\n",
       "                                                               variables=[&#x27;neighbourhood&#x27;])),\n",
       "                                             (&#x27;preprocessor&#x27;,\n",
       "                                              ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                                                transformers=[(&#x27;text&#x27;,\n",
       "                                                                               Pipeline(steps=[(&#x27;text_...\n",
       "                                                                                &#x27;neighbourhood&#x27;,\n",
       "                                                                                &#x27;room_type&#x27;])])),\n",
       "                                             (&#x27;lgbm&#x27;, LGBMRegressor())]),\n",
       "                   param_distributions={&#x27;lgbm__learning_rate&#x27;: [0.1, 0.03,\n",
       "                                                                0.001],\n",
       "                                        &#x27;lgbm__max_depth&#x27;: [-1, 3, 5],\n",
       "                                        &#x27;lgbm__n_estimators&#x27;: [200, 500, 1000],\n",
       "                                        &#x27;lgbm__num_leaves&#x27;: [7, 14, 21],\n",
       "                                        &#x27;preprocessor__text__text_vec__max_features&#x27;: [10,\n",
       "                                                                                       20,\n",
       "                                                                                       50,\n",
       "                                                                                       150]},\n",
       "                   random_state=42, return_train_score=True,\n",
       "                   scoring=&#x27;neg_mean_squared_log_error&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;date_features&#x27;,\n",
       "                 DatetimeFeatures(features_to_extract=[&#x27;year&#x27;, &#x27;month&#x27;,\n",
       "                                                       &#x27;quarter&#x27;, &#x27;day_of_week&#x27;,\n",
       "                                                       &#x27;weekend&#x27;],\n",
       "                                  variables=[&#x27;last_review&#x27;])),\n",
       "                (&#x27;rare&#x27;,\n",
       "                 RareLabelEncoder(tol=0.03, variables=[&#x27;neighbourhood&#x27;])),\n",
       "                (&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;text&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;text_vec&#x27;,\n",
       "                                                                   CountVectorizer(max_features=30,\n",
       "                                                                                   stop_words=&#x27;english&#x27;))]),\n",
       "                                                  &#x27;name&#x27;),\n",
       "                                                 (&#x27;cat&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;encoder&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                                 sparse_output=False))]),\n",
       "                                                  [&#x27;neighbourhood_group&#x27;,\n",
       "                                                   &#x27;neighbourhood&#x27;,\n",
       "                                                   &#x27;room_type&#x27;])])),\n",
       "                (&#x27;lgbm&#x27;, LGBMRegressor())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DatetimeFeatures</label><div class=\"sk-toggleable__content\"><pre>DatetimeFeatures(features_to_extract=[&#x27;year&#x27;, &#x27;month&#x27;, &#x27;quarter&#x27;, &#x27;day_of_week&#x27;,\n",
       "                                      &#x27;weekend&#x27;],\n",
       "                 variables=[&#x27;last_review&#x27;])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RareLabelEncoder</label><div class=\"sk-toggleable__content\"><pre>RareLabelEncoder(tol=0.03, variables=[&#x27;neighbourhood&#x27;])</pre></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;text&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;text_vec&#x27;,\n",
       "                                                  CountVectorizer(max_features=30,\n",
       "                                                                  stop_words=&#x27;english&#x27;))]),\n",
       "                                 &#x27;name&#x27;),\n",
       "                                (&#x27;cat&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;encoder&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                sparse_output=False))]),\n",
       "                                 [&#x27;neighbourhood_group&#x27;, &#x27;neighbourhood&#x27;,\n",
       "                                  &#x27;room_type&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">text</label><div class=\"sk-toggleable__content\"><pre>name</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(max_features=30, stop_words=&#x27;english&#x27;)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat</label><div class=\"sk-toggleable__content\"><pre>[&#x27;neighbourhood_group&#x27;, &#x27;neighbourhood&#x27;, &#x27;room_type&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;, sparse_output=False)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;minimum_nights&#x27;, &#x27;number_of_reviews&#x27;, &#x27;reviews_per_month&#x27;, &#x27;calculated_host_listings_count&#x27;, &#x27;availability_365&#x27;, &#x27;last_review_year&#x27;, &#x27;last_review_month&#x27;, &#x27;last_review_quarter&#x27;, &#x27;last_review_day_of_week&#x27;, &#x27;last_review_weekend&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMRegressor</label><div class=\"sk-toggleable__content\"><pre>LGBMRegressor()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[('date_features',\n",
       "                                              DatetimeFeatures(features_to_extract=['year',\n",
       "                                                                                    'month',\n",
       "                                                                                    'quarter',\n",
       "                                                                                    'day_of_week',\n",
       "                                                                                    'weekend'],\n",
       "                                                               variables=['last_review'])),\n",
       "                                             ('rare',\n",
       "                                              RareLabelEncoder(tol=0.03,\n",
       "                                                               variables=['neighbourhood'])),\n",
       "                                             ('preprocessor',\n",
       "                                              ColumnTransformer(remainder='passthrough',\n",
       "                                                                transformers=[('text',\n",
       "                                                                               Pipeline(steps=[('text_...\n",
       "                                                                                'neighbourhood',\n",
       "                                                                                'room_type'])])),\n",
       "                                             ('lgbm', LGBMRegressor())]),\n",
       "                   param_distributions={'lgbm__learning_rate': [0.1, 0.03,\n",
       "                                                                0.001],\n",
       "                                        'lgbm__max_depth': [-1, 3, 5],\n",
       "                                        'lgbm__n_estimators': [200, 500, 1000],\n",
       "                                        'lgbm__num_leaves': [7, 14, 21],\n",
       "                                        'preprocessor__text__text_vec__max_features': [10,\n",
       "                                                                                       20,\n",
       "                                                                                       50,\n",
       "                                                                                       150]},\n",
       "                   random_state=42, return_train_score=True,\n",
       "                   scoring='neg_mean_squared_log_error', verbose=1)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_tune.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7a129ce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/best_lgbm.pkl']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "best_lgbm = lgbm_tune.best_estimator_\n",
    "dump(best_lgbm, '../models/best_lgbm.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f3d25d33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.004814814664190133"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_tune.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8a4236eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series((lgbm_tune.predict(X_test) - y_test)).hist(grid=False, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce29e06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
